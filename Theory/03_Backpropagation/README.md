# BackPropagation(역전파법)
앞먹임 신경망(Feedforward neural network)의 학습에서 가중치와 바이어스에 대한 오차함수의 미분을 계산, 역전파법은 이 미분을 효율적으로 계산하는 방법 <br>

## 기울기 계산의 어려움 
경사 하강법을 실행하기 위해선 오차함수(E(w))의 기울기를 계산 해야 함

기울기 벡터의 각 성분은 각 층의 결합 가중치와 각 유닛의 바이어스에 대한 오차함수의 편미분 

그러나 이들 미분을 계산하는 것은 중간층, 특히 입력이 가까운 깊은 층의 파라미터일수록 까다로워 짐

프로그래밍하기 까다로운 동시에 계산 비용도 매우 커 이 문제를 해결하는 방법으로 쓰이는 것이 **역전파법(backpropagation)**

<br>

## 기울기 소실 문제
순전파 및 역전파 계산은 모두 층 단위의 행렬 계산이며 식의 형태가 매우 닮아있음. But, 순전파는 비선형 계산인데 비해, 역전파는 선형 계산이라는 차이가 존재 <br>

선형 계산을 여러번 반복하게 되면 각 층의 가중치의 값이 크면 델타가 각 층을 거쳐 전달되는 도중에 급속하게 커지거나(발산) 혹은 반대로 기울기가 작으면 급속하게 작아져 0이 되어 버림 <br>

이러한 문제를 **기울기 소실 문제(vanishing gradient problem)** . 이 문제는 여러 층을 갖는 신경망의 학습을 방해하는 큰 장애물 --> 이를 회피하는 방법으로 **사전훈련** 이라는 방법이 존재 <br>

## 사전훈련
여러 층으로 구성된 앞먹임 신경망을 기울기 소실 문제로 인해 일반적으로 학습이 잘 되지 않음. 이러한 문제를 해결하기 위한 방법이 사전 훈련. 

앞먹임 신경망의 지도 학습법에서는 일반적으로 학습을 시작할 때의 초기 가중치를 랜덤값으로 초기화하는데 사전훈련법의 기본 아이디어는 이 초기값을 좀 더 '좋은 값으로 정하면 학습이 잘 될 것' 이라는 것

다양한 사전훈련 방법이 있으나 가장 기본적인 것이 자기부호화기를 사용한 방법